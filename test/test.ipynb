{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79f608ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fffe2029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadYoloModel():\n",
    "    model = YOLO(\"yolo11n_best.pt\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "faf5a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadYoloModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9bff7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 704x864 (no detections), 228.2ms\n",
      "Speed: 50.9ms preprocess, 228.2ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 864)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/cggblq8j1gg3s0lvzv4m1chw0000gn/T/ipykernel_87391/2115645553.py:41: RuntimeWarning: invalid value encountered in cast\n",
      "  plt.imshow(overlay.astype(np.uint8))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 2) TIFF mit PIL laden (zuverlässiger als cv2)\n",
    "# --------------------------\n",
    "img_path = \"ausgabe_ndvi_20.tif\"\n",
    "pil_img = Image.open(img_path)\n",
    "\n",
    "# In NumPy umwandeln\n",
    "img = np.array(pil_img)\n",
    "\n",
    "# --------------------------\n",
    "# 3) Sicherstellen, dass YOLO ein 3-Kanal Bild bekommt\n",
    "# --------------------------\n",
    "if img.ndim == 2:\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Falls mehr als 3 Kanäle vorhanden sind (z.B. RGBA, multispektral)\n",
    "if img.ndim == 3 and img.shape[2] > 3:\n",
    "    img = img[:, :, :3]\n",
    "\n",
    "# --------------------------\n",
    "# 4) Prediction ausführen\n",
    "# --------------------------\n",
    "results = model.predict(\n",
    "    source=img,\n",
    "    save=False,\n",
    "    imgsz=864\n",
    ")\n",
    "r = results[0]\n",
    "overlay = img.copy()\n",
    "\n",
    "if r.masks is not None:\n",
    "    masks = r.masks.data.cpu().numpy()\n",
    "\n",
    "    for m in masks:\n",
    "        color = np.random.randint(0, 255, size=3)\n",
    "        overlay[m > 0.5] = (\n",
    "            0.6 * overlay[m > 0.5] + 0.4 * color\n",
    "        )\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(overlay.astype(np.uint8))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5707952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 704x864 (no detections), 252.4ms\n",
      "Speed: 42.3ms preprocess, 252.4ms inference, 10.2ms postprocess per image at shape (1, 3, 704, 864)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'Mauseschaden'}\n",
      "obb: None\n",
      "orig_img: array([[[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        ...,\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        ...,\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        ...,\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        ...,\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        ...,\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        ...,\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]]], shape=(2682, 3387, 3), dtype=float32)\n",
      "orig_shape: (2682, 3387)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: '/Users/martin/uni/mouse/Data-Science-Deployment-Mauseschaden/runs/segment/predict3'\n",
      "speed: {'preprocess': 42.34512499533594, 'inference': 252.44062498677522, 'postprocess': 10.246916965115815}]\n",
      "Keine Masken erkannt.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 2) TIFF mit PIL laden (zuverlässiger als cv2)\n",
    "# --------------------------\n",
    "img_path = \"ausgabe_ndvi_20.tif\"\n",
    "pil_img = Image.open(img_path)\n",
    "\n",
    "# In NumPy umwandeln\n",
    "img = np.array(pil_img)\n",
    "\n",
    "# --------------------------\n",
    "# 3) Sicherstellen, dass YOLO ein 3-Kanal Bild bekommt\n",
    "# --------------------------\n",
    "if img.ndim == 2:\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Falls mehr als 3 Kanäle vorhanden sind (z.B. RGBA, multispektral)\n",
    "if img.ndim == 3 and img.shape[2] > 3:\n",
    "    img = img[:, :, :3]\n",
    "\n",
    "# --------------------------\n",
    "# 4) Prediction ausführen\n",
    "# --------------------------\n",
    "results = model.predict(\n",
    "    source=img,\n",
    "    save=False,\n",
    "    imgsz=864\n",
    ")\n",
    "\n",
    "\n",
    "print(results)\n",
    "\n",
    "# --------------------------\n",
    "# 5) Masken visualisieren\n",
    "# --------------------------\n",
    "result = results[0]\n",
    "\n",
    "masked_img = img.copy()\n",
    "\n",
    "if result.masks is not None:\n",
    "    for mask in result.masks.data:\n",
    "        m = mask.cpu().numpy()\n",
    "        masked_img[m > 0.5] = [255, 0, 0]  # rote Überlagerung\n",
    "\n",
    "    cv2.imwrite(\"prediction_masked.png\", cv2.cvtColor(masked_img, cv2.COLOR_RGB2BGR))\n",
    "    print(\"Maske gespeichert als prediction_masked.png\")\n",
    "else:\n",
    "    print(\"Keine Masken erkannt.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py314",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
